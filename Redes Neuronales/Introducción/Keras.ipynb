{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --user tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "plt.imshow(X_train[0], cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.1717560e-02, -2.9734053e-02, -1.6736817e-02, ...,\n",
       "        -6.8358198e-02,  1.2151822e-03,  1.4967874e-02],\n",
       "       [-1.0498755e-02,  6.7651898e-02, -3.0309752e-02, ...,\n",
       "         5.7629809e-02,  9.5959753e-04,  5.0448015e-02],\n",
       "       [-9.7222626e-05,  1.3338335e-02,  5.7054847e-02, ...,\n",
       "         4.1049510e-02,  6.0225561e-02, -2.2331923e-02],\n",
       "       ...,\n",
       "       [-3.1967659e-02,  4.7909573e-02,  2.8440662e-02, ...,\n",
       "         4.3810651e-02, -2.8171524e-02, -5.8486529e-02],\n",
       "       [-6.6795796e-03,  4.1871928e-02,  1.6673952e-03, ...,\n",
       "         2.2775680e-04,  2.3562044e-02,  7.4207664e-02],\n",
       "       [-1.4877908e-02, -4.7135688e-02, -6.7195460e-02, ...,\n",
       "        -6.0064737e-02, -4.0505879e-02, -3.8753148e-02]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4735 - loss: 1.7807 - val_accuracy: 0.8572 - val_loss: 0.6389\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.6028 - val_accuracy: 0.8961 - val_loss: 0.4077\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.4310 - val_accuracy: 0.9079 - val_loss: 0.3401\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.3635 - val_accuracy: 0.9142 - val_loss: 0.3071\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9077 - loss: 0.3310 - val_accuracy: 0.9195 - val_loss: 0.2848\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.3071 - val_accuracy: 0.9241 - val_loss: 0.2704\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9182 - loss: 0.2863 - val_accuracy: 0.9280 - val_loss: 0.2540\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.2699 - val_accuracy: 0.9320 - val_loss: 0.2438\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9275 - loss: 0.2570 - val_accuracy: 0.9347 - val_loss: 0.2333\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.2419 - val_accuracy: 0.9370 - val_loss: 0.2237\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9323 - loss: 0.2361 - val_accuracy: 0.9399 - val_loss: 0.2151\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.2253 - val_accuracy: 0.9406 - val_loss: 0.2096\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.2204 - val_accuracy: 0.9418 - val_loss: 0.2021\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9409 - loss: 0.2083 - val_accuracy: 0.9463 - val_loss: 0.1944\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.2033 - val_accuracy: 0.9472 - val_loss: 0.1900\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9435 - loss: 0.1968 - val_accuracy: 0.9489 - val_loss: 0.1842\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9460 - loss: 0.1869 - val_accuracy: 0.9500 - val_loss: 0.1787\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1780 - val_accuracy: 0.9517 - val_loss: 0.1726\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9504 - loss: 0.1741 - val_accuracy: 0.9526 - val_loss: 0.1689\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9516 - loss: 0.1667 - val_accuracy: 0.9543 - val_loss: 0.1663\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1619 - val_accuracy: 0.9555 - val_loss: 0.1615\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1590 - val_accuracy: 0.9564 - val_loss: 0.1573\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.1550 - val_accuracy: 0.9583 - val_loss: 0.1526\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.1467 - val_accuracy: 0.9576 - val_loss: 0.1531\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1475 - val_accuracy: 0.9596 - val_loss: 0.1475\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9579 - loss: 0.1467 - val_accuracy: 0.9608 - val_loss: 0.1437\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.1380 - val_accuracy: 0.9617 - val_loss: 0.1413\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9622 - loss: 0.1323 - val_accuracy: 0.9620 - val_loss: 0.1404\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.1315 - val_accuracy: 0.9628 - val_loss: 0.1361\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.1264 - val_accuracy: 0.9636 - val_loss: 0.1338\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1233 - val_accuracy: 0.9632 - val_loss: 0.1316\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.1228 - val_accuracy: 0.9649 - val_loss: 0.1293\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1179 - val_accuracy: 0.9653 - val_loss: 0.1272\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1175 - val_accuracy: 0.9663 - val_loss: 0.1246\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1164 - val_accuracy: 0.9666 - val_loss: 0.1232\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9686 - loss: 0.1112 - val_accuracy: 0.9675 - val_loss: 0.1215\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9690 - loss: 0.1085 - val_accuracy: 0.9673 - val_loss: 0.1196\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.1061 - val_accuracy: 0.9679 - val_loss: 0.1184\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.1015 - val_accuracy: 0.9682 - val_loss: 0.1166\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9722 - loss: 0.1029 - val_accuracy: 0.9688 - val_loss: 0.1151\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.1004 - val_accuracy: 0.9691 - val_loss: 0.1137\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.0987 - val_accuracy: 0.9697 - val_loss: 0.1117\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0939 - val_accuracy: 0.9701 - val_loss: 0.1105\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9744 - loss: 0.0922 - val_accuracy: 0.9699 - val_loss: 0.1091\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.0919 - val_accuracy: 0.9696 - val_loss: 0.1081\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9760 - loss: 0.0890 - val_accuracy: 0.9703 - val_loss: 0.1062\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0850 - val_accuracy: 0.9699 - val_loss: 0.1067\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0855 - val_accuracy: 0.9708 - val_loss: 0.1046\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0796 - val_accuracy: 0.9713 - val_loss: 0.1039\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0804 - val_accuracy: 0.9714 - val_loss: 0.1033\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0806 - val_accuracy: 0.9705 - val_loss: 0.1032\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0788 - val_accuracy: 0.9713 - val_loss: 0.0997\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0744 - val_accuracy: 0.9721 - val_loss: 0.0971\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0721 - val_accuracy: 0.9725 - val_loss: 0.0967\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0687 - val_accuracy: 0.9736 - val_loss: 0.0944\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0673 - val_accuracy: 0.9724 - val_loss: 0.0941\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0660 - val_accuracy: 0.9742 - val_loss: 0.0918\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0619 - val_accuracy: 0.9739 - val_loss: 0.0913\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0596 - val_accuracy: 0.9732 - val_loss: 0.0922\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0612 - val_accuracy: 0.9748 - val_loss: 0.0889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16e807a9160>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.6648799777030945, 0.8654199838638306, 0.8893200159072876, 0.9014599919319153, 0.9093800187110901, 0.9148600101470947, 0.9195399880409241, 0.9238600134849548, 0.9279199838638306, 0.9305400252342224, 0.9334999918937683, 0.9360799789428711, 0.938979983329773, 0.9412199854850769, 0.9432799816131592, 0.9446200132369995, 0.9466000199317932, 0.9480999708175659, 0.9499199986457825, 0.9509400129318237, 0.9526399970054626, 0.9537000060081482, 0.9557200074195862, 0.9571200013160706, 0.9581800103187561, 0.9594200253486633, 0.9607200026512146, 0.961359977722168, 0.9627599716186523, 0.9634199738502502, 0.9648600220680237, 0.964959979057312, 0.9665600061416626, 0.9672399759292603, 0.9680799841880798, 0.9689800143241882, 0.9697399735450745, 0.970579981803894, 0.9712799787521362, 0.9722599983215332, 0.9723799824714661, 0.9730799794197083, 0.9737799763679504, 0.9744200110435486, 0.9748799800872803, 0.9753599762916565, 0.9761599898338318, 0.9767799973487854, 0.976859986782074, 0.9778800010681152], 'loss': [1.3140523433685303, 0.5403558015823364, 0.40948501229286194, 0.3554546535015106, 0.32392585277557373, 0.30126696825027466, 0.28323492407798767, 0.2684813141822815, 0.2557241916656494, 0.24430501461029053, 0.23416949808597565, 0.22463946044445038, 0.21616891026496887, 0.20813417434692383, 0.20052970945835114, 0.19360336661338806, 0.18713122606277466, 0.18102669715881348, 0.17525990307331085, 0.170003280043602, 0.1645464450120926, 0.15976685285568237, 0.15534809231758118, 0.15080349147319794, 0.14672808349132538, 0.14268170297145844, 0.1387862265110016, 0.13526907563209534, 0.1319131851196289, 0.12841780483722687, 0.12527112662792206, 0.12225780636072159, 0.1192592978477478, 0.11643943190574646, 0.1137622818350792, 0.1109638512134552, 0.10852169990539551, 0.10603651404380798, 0.10362037271261215, 0.10124174505472183, 0.09907326102256775, 0.0970725417137146, 0.09487345069646835, 0.09292695671319962, 0.09104164689779282, 0.08930282294750214, 0.08719290792942047, 0.08545244485139847, 0.08378764986991882, 0.08228939771652222], 'val_accuracy': [0.857200026512146, 0.8960999846458435, 0.9078999757766724, 0.9142000079154968, 0.9194999933242798, 0.9240999817848206, 0.9279999732971191, 0.9319999814033508, 0.9347000122070312, 0.9369999766349792, 0.9398999810218811, 0.9405999779701233, 0.9417999982833862, 0.9463000297546387, 0.9472000002861023, 0.9488999843597412, 0.949999988079071, 0.95169997215271, 0.9526000022888184, 0.9542999863624573, 0.9555000066757202, 0.9563999772071838, 0.958299994468689, 0.9575999975204468, 0.9595999717712402, 0.9607999920845032, 0.9617000222206116, 0.9620000123977661, 0.9628000259399414, 0.9635999798774719, 0.9631999731063843, 0.964900016784668, 0.9653000235557556, 0.9663000106811523, 0.9666000008583069, 0.9674999713897705, 0.9672999978065491, 0.9678999781608582, 0.9682000279426575, 0.9688000082969666, 0.9690999984741211, 0.9696999788284302, 0.9700999855995178, 0.9699000120162964, 0.9696000218391418, 0.970300018787384, 0.9699000120162964, 0.97079998254776, 0.9713000059127808, 0.9714000225067139], 'val_loss': [0.6388806700706482, 0.40767571330070496, 0.34012076258659363, 0.30712202191352844, 0.2847594618797302, 0.2703840434551239, 0.2539520859718323, 0.24377404153347015, 0.2332582324743271, 0.22371643781661987, 0.21510392427444458, 0.2095641791820526, 0.20205678045749664, 0.19438867270946503, 0.1900426149368286, 0.18419420719146729, 0.17865213751792908, 0.17256174981594086, 0.16891010105609894, 0.16629981994628906, 0.16146288812160492, 0.1573086529970169, 0.15255595743656158, 0.1531030535697937, 0.14750657975673676, 0.14373154938220978, 0.14134107530117035, 0.14041505753993988, 0.13607002794742584, 0.13377410173416138, 0.13156865537166595, 0.1292634904384613, 0.12721502780914307, 0.12457004189491272, 0.1232340857386589, 0.12149042636156082, 0.11959991604089737, 0.11836382001638412, 0.1165504902601242, 0.11514022201299667, 0.11367589980363846, 0.11166521906852722, 0.11045774817466736, 0.10913331061601639, 0.10810354351997375, 0.10619598627090454, 0.10668174922466278, 0.10461198538541794, 0.10386011004447937, 0.10333607345819473]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6648799777030945,\n",
       "  0.8654199838638306,\n",
       "  0.8893200159072876,\n",
       "  0.9014599919319153,\n",
       "  0.9093800187110901,\n",
       "  0.9148600101470947,\n",
       "  0.9195399880409241,\n",
       "  0.9238600134849548,\n",
       "  0.9279199838638306,\n",
       "  0.9305400252342224,\n",
       "  0.9334999918937683,\n",
       "  0.9360799789428711,\n",
       "  0.938979983329773,\n",
       "  0.9412199854850769,\n",
       "  0.9432799816131592,\n",
       "  0.9446200132369995,\n",
       "  0.9466000199317932,\n",
       "  0.9480999708175659,\n",
       "  0.9499199986457825,\n",
       "  0.9509400129318237,\n",
       "  0.9526399970054626,\n",
       "  0.9537000060081482,\n",
       "  0.9557200074195862,\n",
       "  0.9571200013160706,\n",
       "  0.9581800103187561,\n",
       "  0.9594200253486633,\n",
       "  0.9607200026512146,\n",
       "  0.961359977722168,\n",
       "  0.9627599716186523,\n",
       "  0.9634199738502502,\n",
       "  0.9648600220680237,\n",
       "  0.964959979057312,\n",
       "  0.9665600061416626,\n",
       "  0.9672399759292603,\n",
       "  0.9680799841880798,\n",
       "  0.9689800143241882,\n",
       "  0.9697399735450745,\n",
       "  0.970579981803894,\n",
       "  0.9712799787521362,\n",
       "  0.9722599983215332,\n",
       "  0.9723799824714661,\n",
       "  0.9730799794197083,\n",
       "  0.9737799763679504,\n",
       "  0.9744200110435486,\n",
       "  0.9748799800872803,\n",
       "  0.9753599762916565,\n",
       "  0.9761599898338318,\n",
       "  0.9767799973487854,\n",
       "  0.976859986782074,\n",
       "  0.9778800010681152],\n",
       " 'loss': [1.3140523433685303,\n",
       "  0.5403558015823364,\n",
       "  0.40948501229286194,\n",
       "  0.3554546535015106,\n",
       "  0.32392585277557373,\n",
       "  0.30126696825027466,\n",
       "  0.28323492407798767,\n",
       "  0.2684813141822815,\n",
       "  0.2557241916656494,\n",
       "  0.24430501461029053,\n",
       "  0.23416949808597565,\n",
       "  0.22463946044445038,\n",
       "  0.21616891026496887,\n",
       "  0.20813417434692383,\n",
       "  0.20052970945835114,\n",
       "  0.19360336661338806,\n",
       "  0.18713122606277466,\n",
       "  0.18102669715881348,\n",
       "  0.17525990307331085,\n",
       "  0.170003280043602,\n",
       "  0.1645464450120926,\n",
       "  0.15976685285568237,\n",
       "  0.15534809231758118,\n",
       "  0.15080349147319794,\n",
       "  0.14672808349132538,\n",
       "  0.14268170297145844,\n",
       "  0.1387862265110016,\n",
       "  0.13526907563209534,\n",
       "  0.1319131851196289,\n",
       "  0.12841780483722687,\n",
       "  0.12527112662792206,\n",
       "  0.12225780636072159,\n",
       "  0.1192592978477478,\n",
       "  0.11643943190574646,\n",
       "  0.1137622818350792,\n",
       "  0.1109638512134552,\n",
       "  0.10852169990539551,\n",
       "  0.10603651404380798,\n",
       "  0.10362037271261215,\n",
       "  0.10124174505472183,\n",
       "  0.09907326102256775,\n",
       "  0.0970725417137146,\n",
       "  0.09487345069646835,\n",
       "  0.09292695671319962,\n",
       "  0.09104164689779282,\n",
       "  0.08930282294750214,\n",
       "  0.08719290792942047,\n",
       "  0.08545244485139847,\n",
       "  0.08378764986991882,\n",
       "  0.08228939771652222],\n",
       " 'val_accuracy': [0.857200026512146,\n",
       "  0.8960999846458435,\n",
       "  0.9078999757766724,\n",
       "  0.9142000079154968,\n",
       "  0.9194999933242798,\n",
       "  0.9240999817848206,\n",
       "  0.9279999732971191,\n",
       "  0.9319999814033508,\n",
       "  0.9347000122070312,\n",
       "  0.9369999766349792,\n",
       "  0.9398999810218811,\n",
       "  0.9405999779701233,\n",
       "  0.9417999982833862,\n",
       "  0.9463000297546387,\n",
       "  0.9472000002861023,\n",
       "  0.9488999843597412,\n",
       "  0.949999988079071,\n",
       "  0.95169997215271,\n",
       "  0.9526000022888184,\n",
       "  0.9542999863624573,\n",
       "  0.9555000066757202,\n",
       "  0.9563999772071838,\n",
       "  0.958299994468689,\n",
       "  0.9575999975204468,\n",
       "  0.9595999717712402,\n",
       "  0.9607999920845032,\n",
       "  0.9617000222206116,\n",
       "  0.9620000123977661,\n",
       "  0.9628000259399414,\n",
       "  0.9635999798774719,\n",
       "  0.9631999731063843,\n",
       "  0.964900016784668,\n",
       "  0.9653000235557556,\n",
       "  0.9663000106811523,\n",
       "  0.9666000008583069,\n",
       "  0.9674999713897705,\n",
       "  0.9672999978065491,\n",
       "  0.9678999781608582,\n",
       "  0.9682000279426575,\n",
       "  0.9688000082969666,\n",
       "  0.9690999984741211,\n",
       "  0.9696999788284302,\n",
       "  0.9700999855995178,\n",
       "  0.9699000120162964,\n",
       "  0.9696000218391418,\n",
       "  0.970300018787384,\n",
       "  0.9699000120162964,\n",
       "  0.97079998254776,\n",
       "  0.9713000059127808,\n",
       "  0.9714000225067139],\n",
       " 'val_loss': [0.6388806700706482,\n",
       "  0.40767571330070496,\n",
       "  0.34012076258659363,\n",
       "  0.30712202191352844,\n",
       "  0.2847594618797302,\n",
       "  0.2703840434551239,\n",
       "  0.2539520859718323,\n",
       "  0.24377404153347015,\n",
       "  0.2332582324743271,\n",
       "  0.22371643781661987,\n",
       "  0.21510392427444458,\n",
       "  0.2095641791820526,\n",
       "  0.20205678045749664,\n",
       "  0.19438867270946503,\n",
       "  0.1900426149368286,\n",
       "  0.18419420719146729,\n",
       "  0.17865213751792908,\n",
       "  0.17256174981594086,\n",
       "  0.16891010105609894,\n",
       "  0.16629981994628906,\n",
       "  0.16146288812160492,\n",
       "  0.1573086529970169,\n",
       "  0.15255595743656158,\n",
       "  0.1531030535697937,\n",
       "  0.14750657975673676,\n",
       "  0.14373154938220978,\n",
       "  0.14134107530117035,\n",
       "  0.14041505753993988,\n",
       "  0.13607002794742584,\n",
       "  0.13377410173416138,\n",
       "  0.13156865537166595,\n",
       "  0.1292634904384613,\n",
       "  0.12721502780914307,\n",
       "  0.12457004189491272,\n",
       "  0.1232340857386589,\n",
       "  0.12149042636156082,\n",
       "  0.11959991604089737,\n",
       "  0.11836382001638412,\n",
       "  0.1165504902601242,\n",
       "  0.11514022201299667,\n",
       "  0.11367589980363846,\n",
       "  0.11166521906852722,\n",
       "  0.11045774817466736,\n",
       "  0.10913331061601639,\n",
       "  0.10810354351997375,\n",
       "  0.10619598627090454,\n",
       "  0.10668174922466278,\n",
       "  0.10461198538541794,\n",
       "  0.10386011004447937,\n",
       "  0.10333607345819473]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.66488</td>\n",
       "      <td>1.314052</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>0.638881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86542</td>\n",
       "      <td>0.540356</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.407676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88932</td>\n",
       "      <td>0.409485</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.340121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90146</td>\n",
       "      <td>0.355455</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.307122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90938</td>\n",
       "      <td>0.323926</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.284759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91486</td>\n",
       "      <td>0.301267</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.270384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.91954</td>\n",
       "      <td>0.283235</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.253952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92386</td>\n",
       "      <td>0.268481</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.243774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92792</td>\n",
       "      <td>0.255724</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.233258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93054</td>\n",
       "      <td>0.244305</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.223716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93350</td>\n",
       "      <td>0.234169</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>0.215104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93608</td>\n",
       "      <td>0.224639</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.209564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93898</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.202057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94122</td>\n",
       "      <td>0.208134</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.194389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94328</td>\n",
       "      <td>0.200530</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.190043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94462</td>\n",
       "      <td>0.193603</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.184194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94660</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.178652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94810</td>\n",
       "      <td>0.181027</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.172562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.94992</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.168910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95094</td>\n",
       "      <td>0.170003</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>0.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.164546</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.161463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95370</td>\n",
       "      <td>0.159767</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.157309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95572</td>\n",
       "      <td>0.155348</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.152556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95712</td>\n",
       "      <td>0.150803</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.153103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95818</td>\n",
       "      <td>0.146728</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.147507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95942</td>\n",
       "      <td>0.142682</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.143732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.96072</td>\n",
       "      <td>0.138786</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.141341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96136</td>\n",
       "      <td>0.135269</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.140415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96276</td>\n",
       "      <td>0.131913</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.136070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96342</td>\n",
       "      <td>0.128418</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.133774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96486</td>\n",
       "      <td>0.125271</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.131569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96496</td>\n",
       "      <td>0.122258</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.129263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96656</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.127215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96724</td>\n",
       "      <td>0.116439</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.124570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96808</td>\n",
       "      <td>0.113762</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.123234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96898</td>\n",
       "      <td>0.110964</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.121490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96974</td>\n",
       "      <td>0.108522</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.97058</td>\n",
       "      <td>0.106037</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.118364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97128</td>\n",
       "      <td>0.103620</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.116550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97226</td>\n",
       "      <td>0.101242</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.115140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97238</td>\n",
       "      <td>0.099073</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.113676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97308</td>\n",
       "      <td>0.097073</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.111665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97378</td>\n",
       "      <td>0.094873</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.110458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97442</td>\n",
       "      <td>0.092927</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.109133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97488</td>\n",
       "      <td>0.091042</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.108104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97536</td>\n",
       "      <td>0.089303</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.106196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97616</td>\n",
       "      <td>0.087193</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.106682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97678</td>\n",
       "      <td>0.085452</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>0.104612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97686</td>\n",
       "      <td>0.083788</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.103860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97788</td>\n",
       "      <td>0.082289</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.103336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.66488  1.314052        0.8572  0.638881\n",
       "1    0.86542  0.540356        0.8961  0.407676\n",
       "2    0.88932  0.409485        0.9079  0.340121\n",
       "3    0.90146  0.355455        0.9142  0.307122\n",
       "4    0.90938  0.323926        0.9195  0.284759\n",
       "5    0.91486  0.301267        0.9241  0.270384\n",
       "6    0.91954  0.283235        0.9280  0.253952\n",
       "7    0.92386  0.268481        0.9320  0.243774\n",
       "8    0.92792  0.255724        0.9347  0.233258\n",
       "9    0.93054  0.244305        0.9370  0.223716\n",
       "10   0.93350  0.234169        0.9399  0.215104\n",
       "11   0.93608  0.224639        0.9406  0.209564\n",
       "12   0.93898  0.216169        0.9418  0.202057\n",
       "13   0.94122  0.208134        0.9463  0.194389\n",
       "14   0.94328  0.200530        0.9472  0.190043\n",
       "15   0.94462  0.193603        0.9489  0.184194\n",
       "16   0.94660  0.187131        0.9500  0.178652\n",
       "17   0.94810  0.181027        0.9517  0.172562\n",
       "18   0.94992  0.175260        0.9526  0.168910\n",
       "19   0.95094  0.170003        0.9543  0.166300\n",
       "20   0.95264  0.164546        0.9555  0.161463\n",
       "21   0.95370  0.159767        0.9564  0.157309\n",
       "22   0.95572  0.155348        0.9583  0.152556\n",
       "23   0.95712  0.150803        0.9576  0.153103\n",
       "24   0.95818  0.146728        0.9596  0.147507\n",
       "25   0.95942  0.142682        0.9608  0.143732\n",
       "26   0.96072  0.138786        0.9617  0.141341\n",
       "27   0.96136  0.135269        0.9620  0.140415\n",
       "28   0.96276  0.131913        0.9628  0.136070\n",
       "29   0.96342  0.128418        0.9636  0.133774\n",
       "30   0.96486  0.125271        0.9632  0.131569\n",
       "31   0.96496  0.122258        0.9649  0.129263\n",
       "32   0.96656  0.119259        0.9653  0.127215\n",
       "33   0.96724  0.116439        0.9663  0.124570\n",
       "34   0.96808  0.113762        0.9666  0.123234\n",
       "35   0.96898  0.110964        0.9675  0.121490\n",
       "36   0.96974  0.108522        0.9673  0.119600\n",
       "37   0.97058  0.106037        0.9679  0.118364\n",
       "38   0.97128  0.103620        0.9682  0.116550\n",
       "39   0.97226  0.101242        0.9688  0.115140\n",
       "40   0.97238  0.099073        0.9691  0.113676\n",
       "41   0.97308  0.097073        0.9697  0.111665\n",
       "42   0.97378  0.094873        0.9701  0.110458\n",
       "43   0.97442  0.092927        0.9699  0.109133\n",
       "44   0.97488  0.091042        0.9696  0.108104\n",
       "45   0.97536  0.089303        0.9703  0.106196\n",
       "46   0.97616  0.087193        0.9699  0.106682\n",
       "47   0.97678  0.085452        0.9708  0.104612\n",
       "48   0.97686  0.083788        0.9713  0.103860\n",
       "49   0.97788  0.082289        0.9714  0.103336"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9701 - loss: 0.0975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08395563066005707, 0.974399983882904]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.4106176e-06, 1.2644873e-08, 3.9400395e-05, 3.2264643e-04,\n",
       "        1.9682092e-08, 3.6479928e-06, 8.9496978e-12, 9.9959785e-01,\n",
       "        4.2323186e-06, 2.8794839e-05]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAba0lEQVR4nO3df2zU9R3H8dfxoydIe6zW9npSWEGBKdJNBl2DMpSG0iUMhBj8sQTUwcDiBswfqVFRt6QbJs4fYbLFjeoC/loEIpksWmyJrrBRQULcGkq6UQItk4S7UqAl9LM/CDdPWuB73PHutc9H8k3o3ffTe/v1S598e9erzznnBADAFdbPegAAQN9EgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIkB1gN8XWdnpw4dOqT09HT5fD7rcQAAHjnn1NraqlAopH79ur/O6XEBOnTokPLy8qzHAABcpqamJg0bNqzb+3tcgNLT0yWdHTwjI8N4GgCAV5FIRHl5edGv591JWoBWr16t559/Xs3NzSooKNArr7yiSZMmXXTduW+7ZWRkECAASGEXexolKS9CePvtt7VixQqtXLlSn332mQoKClRSUqIjR44k4+EAACkoKQF64YUXtHDhQt1///268cYbtWbNGg0ePFh//OMfk/FwAIAUlPAAdXR0qK6uTsXFxf9/kH79VFxcrNra2vP2b29vVyQSidkAAL1fwgP05Zdf6syZM8rJyYm5PScnR83NzeftX1FRoUAgEN14BRwA9A3mP4haXl6ucDgc3ZqamqxHAgBcAQl/FVxWVpb69++vlpaWmNtbWloUDAbP29/v98vv9yd6DABAD5fwK6C0tDRNmDBBVVVV0ds6OztVVVWloqKiRD8cACBFJeXngFasWKH58+fru9/9riZNmqQXX3xRbW1tuv/++5PxcACAFJSUAM2bN0///e9/9fTTT6u5uVnf/va3tWXLlvNemAAA6Lt8zjlnPcRXRSIRBQIBhcNh3gkBAFLQpX4dN38VHACgbyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATA6wHAC5m3bp1nte0tbXF9Vh1dXWe1/z+97+P67G8euqppzyvueOOO+J6rKlTp8a1DvCCKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITPOeesh/iqSCSiQCCgcDisjIwM63GQYA899JDnNb/73e+SMEnfcOONN8a17pNPPvG8JhAIxPVY6H0u9es4V0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIkB1gMgdfXGNxb9zne+43nN3LlzPa/Zt2+f5zWvv/665zVffPGF5zWS9Oc//9nzmgcffDCux0LfxRUQAMAEAQIAmEh4gJ555hn5fL6YbezYsYl+GABAikvKc0A33XSTPvroo/8/yACeagIAxEpKGQYMGKBgMJiMTw0A6CWS8hzQvn37FAqFNHLkSN133306cOBAt/u2t7crEonEbACA3i/hASosLFRlZaW2bNmiV199VY2NjbrtttvU2tra5f4VFRUKBALRLS8vL9EjAQB6oIQHqLS0VHfddZfGjx+vkpIS/eUvf9GxY8f0zjvvdLl/eXm5wuFwdGtqakr0SACAHijprw4YOnSoRo8erYaGhi7v9/v98vv9yR4DANDDJP3ngI4fP679+/crNzc32Q8FAEghCQ/QI488opqaGv373//W3/72N915553q37+/7rnnnkQ/FAAghSX8W3AHDx7UPffco6NHj+raa6/Vrbfequ3bt+vaa69N9EMBAFJYwgP01ltvJfpTIsku9DL5C3nttdcSPEnXJk6c6HnNli1b4nqswYMHe16Tlpbmec2ZM2c8r+nuedQL+fTTTz2vkaQvv/wyrnWAF7wXHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIum/kA49X7xvPOmc87wmnjcW/eijjzyvGTJkiOc1V1JlZaXnNf/4xz8SP0g3Zs2adcUeC30XV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwbthQ7fccktc6+J5F+20tDTPawYNGuR5TU/32muveV7T0dGRhEkAO1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmeDNSxC0QCFiP0CP86U9/8rzm888/T8Ik55s+fXpc60aNGpXgSYDzcQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgzUiBr9i1a5fnNT/5yU88r2lvb/e8Jjc31/Oal156yfMaSRo4cGBc6wAvuAICAJggQAAAE54DtG3bNs2cOVOhUEg+n08bN26Mud85p6efflq5ubkaNGiQiouLtW/fvkTNCwDoJTwHqK2tTQUFBVq9enWX969atUovv/yy1qxZox07dujqq69WSUmJTp06ddnDAgB6D88vQigtLVVpaWmX9znn9OKLL+rJJ5/UrFmzJElvvPGGcnJytHHjRt19992XNy0AoNdI6HNAjY2Nam5uVnFxcfS2QCCgwsJC1dbWdrmmvb1dkUgkZgMA9H4JDVBzc7MkKScnJ+b2nJyc6H1fV1FRoUAgEN3y8vISORIAoIcyfxVceXm5wuFwdGtqarIeCQBwBSQ0QMFgUJLU0tISc3tLS0v0vq/z+/3KyMiI2QAAvV9CA5Sfn69gMKiqqqrobZFIRDt27FBRUVEiHwoAkOI8vwru+PHjamhoiH7c2Nio3bt3KzMzU8OHD9eyZcv0y1/+UjfccIPy8/P11FNPKRQKafbs2YmcGwCQ4jwHaOfOnbr99tujH69YsUKSNH/+fFVWVuqxxx5TW1ubFi1apGPHjunWW2/Vli1bdNVVVyVuagBAyvMcoKlTp8o51+39Pp9Pzz33nJ577rnLGgyw0N2PC1xIPG8sGo/Fixd7XjN69OgkTAIkhvmr4AAAfRMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMeH43bCAVPPDAA3Gte/vttxM8SdeWL1/uec1jjz2WhEkAO1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmeDNS9HjHjx/3vOaDDz6I67FOnTrleU1OTo7nNU888YTnNWlpaZ7XAD0ZV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAnejBQ93l133eV5zZEjR5IwSdd++tOfel6TmZmZhEmA1MIVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggjcjxRVVV1fneU11dXXiB+nGnDlzPK9ZsWJFEiYBej+ugAAAJggQAMCE5wBt27ZNM2fOVCgUks/n08aNG2PuX7BggXw+X8w2Y8aMRM0LAOglPAeora1NBQUFWr16dbf7zJgxQ4cPH45ub7755mUNCQDofTy/CKG0tFSlpaUX3Mfv9ysYDMY9FACg90vKc0DV1dXKzs7WmDFjtGTJEh09erTbfdvb2xWJRGI2AEDvl/AAzZgxQ2+88Yaqqqr061//WjU1NSotLdWZM2e63L+iokKBQCC65eXlJXokAEAPlPCfA7r77rujf7755ps1fvx4jRo1StXV1Zo2bdp5+5eXl8f8HEUkEiFCANAHJP1l2CNHjlRWVpYaGhq6vN/v9ysjIyNmAwD0fkkP0MGDB3X06FHl5uYm+6EAACnE87fgjh8/HnM109jYqN27dyszM1OZmZl69tlnNXfuXAWDQe3fv1+PPfaYrr/+epWUlCR0cABAavMcoJ07d+r222+Pfnzu+Zv58+fr1Vdf1Z49e/T666/r2LFjCoVCmj59un7xi1/I7/cnbmoAQMrzHKCpU6fKOdft/X/9618vayCkjpMnT3peU15e7nlNR0eH5zXxmjBhguc1aWlpSZgE6P14LzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYSPiv5EbfsWbNGs9rqqqqkjDJ+R544IG41n3118MDSC6ugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEz7nnLMe4qsikYgCgYDC4bAyMjKsx8EFDBo0yPOajo6OJExyvnA4HNe6IUOGJHgSoO+51K/jXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYGWA8AJMPx48fjWtevX+/6N5nf749rXf/+/T2vOXPmjOc17e3tntfE4+TJk3Gte+mllxI8SeLE8/9Ikp544gnPawYOHBjXY11M7/rbBgBIGQQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACd6MFL3SddddZz1Cj7B48eK41oVCIc9rmpubPa/57W9/63kNLk88fzd+/OMfJ2ESroAAAEYIEADAhKcAVVRUaOLEiUpPT1d2drZmz56t+vr6mH1OnTqlsrIyXXPNNRoyZIjmzp2rlpaWhA4NAEh9ngJUU1OjsrIybd++XR9++KFOnz6t6dOnq62tLbrP8uXL9f777+vdd99VTU2NDh06pDlz5iR8cABAavP0IoQtW7bEfFxZWans7GzV1dVpypQpCofD+sMf/qD169frjjvukCStXbtW3/rWt7R9+3Z973vfS9zkAICUdlnPAYXDYUlSZmamJKmurk6nT59WcXFxdJ+xY8dq+PDhqq2t7fJztLe3KxKJxGwAgN4v7gB1dnZq2bJlmjx5ssaNGyfp7Msw09LSNHTo0Jh9c3Jyun2JZkVFhQKBQHTLy8uLdyQAQAqJO0BlZWXau3ev3nrrrcsaoLy8XOFwOLo1NTVd1ucDAKSGuH4QdenSpdq8ebO2bdumYcOGRW8PBoPq6OjQsWPHYq6CWlpaFAwGu/xcfr9ffr8/njEAACnM0xWQc05Lly7Vhg0btHXrVuXn58fcP2HCBA0cOFBVVVXR2+rr63XgwAEVFRUlZmIAQK/g6QqorKxM69ev16ZNm5Senh59XicQCGjQoEEKBAJ68MEHtWLFCmVmZiojI0MPP/ywioqKeAUcACCGpwC9+uqrkqSpU6fG3L527VotWLBAkvSb3/xG/fr109y5c9Xe3q6SkhLe7wkAcB6fc85ZD/FVkUhEgUBA4XBYGRkZ1uPgAuJ5g8K1a9cmYRL0JQMGeH/qun///kmYpGvn/jHuxZV8imLy5Mme14wcOdLT/pf6dZz3ggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJuH4jKiBJr732muc1U6ZM8bymo6PD85or6fPPP/e8pqf/ipJHH33U85rrr78+CZOc74c//KHnNdnZ2UmYBJeLKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITPOeesh/iqSCSiQCCgcDisjIwM63EAAB5d6tdxroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE54CVFFRoYkTJyo9PV3Z2dmaPXu26uvrY/aZOnWqfD5fzLZ48eKEDg0ASH2eAlRTU6OysjJt375dH374oU6fPq3p06erra0tZr+FCxfq8OHD0W3VqlUJHRoAkPoGeNl5y5YtMR9XVlYqOztbdXV1mjJlSvT2wYMHKxgMJmZCAECvdFnPAYXDYUlSZmZmzO3r1q1TVlaWxo0bp/Lycp04caLbz9He3q5IJBKzAQB6P09XQF/V2dmpZcuWafLkyRo3blz09nvvvVcjRoxQKBTSnj179Pjjj6u+vl7vvfdel5+noqJCzz77bLxjAABSlM855+JZuGTJEn3wwQf65JNPNGzYsG7327p1q6ZNm6aGhgaNGjXqvPvb29vV3t4e/TgSiSgvL0/hcFgZGRnxjAYAMBSJRBQIBC76dTyuK6ClS5dq8+bN2rZt2wXjI0mFhYWS1G2A/H6//H5/PGMAAFKYpwA55/Twww9rw4YNqq6uVn5+/kXX7N69W5KUm5sb14AAgN7JU4DKysq0fv16bdq0Senp6WpubpYkBQIBDRo0SPv379f69ev1gx/8QNdcc4327Nmj5cuXa8qUKRo/fnxS/gMAAKnJ03NAPp+vy9vXrl2rBQsWqKmpST/60Y+0d+9etbW1KS8vT3feeaeefPLJS34+51K/dwgA6JmS8hzQxVqVl5enmpoaL58SANBH8V5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATA6wH+DrnnCQpEokYTwIAiMe5r9/nvp53p8cFqLW1VZKUl5dnPAkA4HK0trYqEAh0e7/PXSxRV1hnZ6cOHTqk9PR0+Xy+mPsikYjy8vLU1NSkjIwMowntcRzO4jicxXE4i+NwVk84Ds45tba2KhQKqV+/7p/p6XFXQP369dOwYcMuuE9GRkafPsHO4TicxXE4i+NwFsfhLOvjcKErn3N4EQIAwAQBAgCYSKkA+f1+rVy5Un6/33oUUxyHszgOZ3EczuI4nJVKx6HHvQgBANA3pNQVEACg9yBAAAATBAgAYIIAAQBMpEyAVq9erW9+85u66qqrVFhYqL///e/WI11xzzzzjHw+X8w2duxY67GSbtu2bZo5c6ZCoZB8Pp82btwYc79zTk8//bRyc3M1aNAgFRcXa9++fTbDJtHFjsOCBQvOOz9mzJhhM2ySVFRUaOLEiUpPT1d2drZmz56t+vr6mH1OnTqlsrIyXXPNNRoyZIjmzp2rlpYWo4mT41KOw9SpU887HxYvXmw0cddSIkBvv/22VqxYoZUrV+qzzz5TQUGBSkpKdOTIEevRrribbrpJhw8fjm6ffPKJ9UhJ19bWpoKCAq1evbrL+1etWqWXX35Za9as0Y4dO3T11VerpKREp06dusKTJtfFjoMkzZgxI+b8ePPNN6/ghMlXU1OjsrIybd++XR9++KFOnz6t6dOnq62tLbrP8uXL9f777+vdd99VTU2NDh06pDlz5hhOnXiXchwkaeHChTHnw6pVq4wm7oZLAZMmTXJlZWXRj8+cOeNCoZCrqKgwnOrKW7lypSsoKLAew5Qkt2HDhujHnZ2dLhgMuueffz5627Fjx5zf73dvvvmmwYRXxtePg3POzZ8/382aNctkHitHjhxxklxNTY1z7uz/+4EDB7p33303us8///lPJ8nV1tZajZl0Xz8Ozjn3/e9/3/3sZz+zG+oS9PgroI6ODtXV1am4uDh6W79+/VRcXKza2lrDyWzs27dPoVBII0eO1H333acDBw5Yj2SqsbFRzc3NMedHIBBQYWFhnzw/qqurlZ2drTFjxmjJkiU6evSo9UhJFQ6HJUmZmZmSpLq6Op0+fTrmfBg7dqyGDx/eq8+Hrx+Hc9atW6esrCyNGzdO5eXlOnHihMV43epxb0b6dV9++aXOnDmjnJycmNtzcnL0r3/9y2gqG4WFhaqsrNSYMWN0+PBhPfvss7rtttu0d+9epaenW49norm5WZK6PD/O3ddXzJgxQ3PmzFF+fr7279+vJ554QqWlpaqtrVX//v2tx0u4zs5OLVu2TJMnT9a4ceMknT0f0tLSNHTo0Jh9e/P50NVxkKR7771XI0aMUCgU0p49e/T444+rvr5e7733nuG0sXp8gPB/paWl0T+PHz9ehYWFGjFihN555x09+OCDhpOhJ7j77rujf7755ps1fvx4jRo1StXV1Zo2bZrhZMlRVlamvXv39onnQS+ku+OwaNGi6J9vvvlm5ebmatq0adq/f79GjRp1pcfsUo//FlxWVpb69+9/3qtYWlpaFAwGjabqGYYOHarRo0eroaHBehQz584Bzo/zjRw5UllZWb3y/Fi6dKk2b96sjz/+OObXtwSDQXV0dOjYsWMx+/fW86G749CVwsJCSepR50OPD1BaWpomTJigqqqq6G2dnZ2qqqpSUVGR4WT2jh8/rv379ys3N9d6FDP5+fkKBoMx50ckEtGOHTv6/Plx8OBBHT16tFedH845LV26VBs2bNDWrVuVn58fc/+ECRM0cODAmPOhvr5eBw4c6FXnw8WOQ1d2794tST3rfLB+FcSleOutt5zf73eVlZXuiy++cIsWLXJDhw51zc3N1qNdUT//+c9ddXW1a2xsdJ9++qkrLi52WVlZ7siRI9ajJVVra6vbtWuX27Vrl5PkXnjhBbdr1y73n//8xznn3K9+9Ss3dOhQt2nTJrdnzx43a9Ysl5+f706ePGk8eWJd6Di0tra6Rx55xNXW1rrGxkb30UcfuVtuucXdcMMN7tSpU9ajJ8ySJUtcIBBw1dXV7vDhw9HtxIkT0X0WL17shg8f7rZu3ep27tzpioqKXFFRkeHUiXex49DQ0OCee+45t3PnTtfY2Og2bdrkRo4c6aZMmWI8eayUCJBzzr3yyitu+PDhLi0tzU2aNMlt377deqQrbt68eS43N9elpaW56667zs2bN881NDRYj5V0H3/8sZN03jZ//nzn3NmXYj/11FMuJyfH+f1+N23aNFdfX287dBJc6DicOHHCTZ8+3V177bVu4MCBbsSIEW7hwoW97h9pXf33S3Jr166N7nPy5En30EMPuW984xtu8ODB7s4773SHDx+2GzoJLnYcDhw44KZMmeIyMzOd3+93119/vXv00UddOBy2Hfxr+HUMAAATPf45IABA70SAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPgf5s/ISvGtzRsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 969,    0,    1,    0,    1,    0,    4,    3,    2,    0],\n",
       "       [   0, 1120,    3,    1,    0,    2,    3,    1,    5,    0],\n",
       "       [   4,    1, 1006,    4,    3,    0,    1,    7,    6,    0],\n",
       "       [   0,    0,    7,  980,    0,    5,    0,    9,    6,    3],\n",
       "       [   1,    0,    5,    0,  958,    0,    2,    2,    1,   13],\n",
       "       [   3,    1,    0,    6,    1,  861,    8,    1,    8,    3],\n",
       "       [   5,    3,    1,    1,    4,    5,  932,    2,    5,    0],\n",
       "       [   0,    6,    7,    1,    1,    1,    0, 1003,    1,    8],\n",
       "       [   4,    0,    3,    6,    3,    5,    4,    6,  943,    0],\n",
       "       [   5,    6,    0,    4,    8,    2,    1,   10,    1,  972]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m  1/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 118ms/step - loss: 6.9568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 1.9784 - val_loss: 0.8075\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.4974 - val_loss: 0.4873\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.4321 - val_loss: 0.4650\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4308 - val_loss: 0.4504\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.4244 - val_loss: 0.4386\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4244 - val_loss: 0.4467\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.3989 - val_loss: 0.4272\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.3808 - val_loss: 0.4196\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 0.4030 - val_loss: 0.4130\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.3885 - val_loss: 0.4142\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.3970 - val_loss: 0.4104\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.3677 - val_loss: 0.4059\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.3875 - val_loss: 0.4046\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.3943 - val_loss: 0.4033\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.3741 - val_loss: 0.4053\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 0.3819 - val_loss: 0.3906\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 0.3597 - val_loss: 0.3994\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.3673 - val_loss: 0.3919\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.3645 - val_loss: 0.3905\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.3693 - val_loss: 0.3834\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.3676\n",
      "0.38323327898979187\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.689587 ],\n",
       "       [ 1.5174265],\n",
       "       [-0.646924 ],\n",
       "       [ 1.4223123],\n",
       "       [ 2.91821  ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3634\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.3663\n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.3585\n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.3729\n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.3669\n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.3441\n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.3729\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 0.3463\n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3703\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.3639\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.3495\n",
      "Epoch 12/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 0.3626\n",
      "Epoch 13/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 0.3515\n",
      "Epoch 14/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.3567\n",
      "Epoch 15/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.3310\n",
      "Epoch 16/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3419\n",
      "Epoch 17/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.3422\n",
      "Epoch 18/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3357\n",
      "Epoch 19/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3476\n",
      "Epoch 20/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.3959\n",
      "Epoch 21/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 0.3211\n",
      "Epoch 22/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.3549\n",
      "Epoch 23/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 0.3343\n",
      "Epoch 24/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.3358\n",
      "Epoch 25/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.3348\n",
      "Epoch 26/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.3357\n",
      "Epoch 27/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 0.3372\n",
      "Epoch 28/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.3216\n",
      "Epoch 29/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 0.3230\n",
      "Epoch 30/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 0.3141\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 0.3248 - val_loss: 0.3461\n",
      "Epoch 2/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.3341 - val_loss: 0.3581\n",
      "Epoch 3/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.3377 - val_loss: 0.3494\n",
      "Epoch 4/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 0.3413 - val_loss: 0.3457\n",
      "Epoch 5/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3346 - val_loss: 0.6997\n",
      "Epoch 6/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.3449 - val_loss: 0.3442\n",
      "Epoch 7/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.3399 - val_loss: 0.3673\n",
      "Epoch 8/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.3328 - val_loss: 0.3407\n",
      "Epoch 9/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.3346 - val_loss: 0.3469\n",
      "Epoch 10/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.3219 - val_loss: 0.3544\n",
      "Epoch 11/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.3130 - val_loss: 0.3474\n",
      "Epoch 12/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.3113 - val_loss: 0.3432\n",
      "Epoch 13/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.3344 - val_loss: 0.3415\n",
      "Epoch 14/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.3619 - val_loss: 0.3403\n",
      "Epoch 15/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.3050 - val_loss: 0.3405\n",
      "Epoch 16/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.3245 - val_loss: 0.3380\n",
      "Epoch 17/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.3149 - val_loss: 0.3384\n",
      "Epoch 18/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.3281 - val_loss: 0.3459\n",
      "Epoch 19/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.3143 - val_loss: 0.3407\n",
      "Epoch 20/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.3146 - val_loss: 0.3502\n",
      "Epoch 21/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.3045 - val_loss: 0.3410\n",
      "Epoch 22/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.3162 - val_loss: 0.3414\n",
      "Epoch 23/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.3121 - val_loss: 0.3477\n",
      "Epoch 24/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.3259 - val_loss: 0.3417\n",
      "Epoch 25/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.3057 - val_loss: 0.3500\n",
      "Epoch 26/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.3123 - val_loss: 0.3358\n",
      "Epoch 27/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.3165 - val_loss: 0.3341\n",
      "Epoch 28/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.3219 - val_loss: 0.3462\n",
      "Epoch 29/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.3153 - val_loss: 0.3536\n",
      "Epoch 30/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.3101 - val_loss: 0.3459\n",
      "Epoch 31/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.3160 - val_loss: 0.3385\n",
      "Epoch 32/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.3025 - val_loss: 0.3499\n",
      "Epoch 33/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.3156 - val_loss: 0.3355\n",
      "Epoch 34/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 0.3082 - val_loss: 0.3365\n",
      "Epoch 35/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.3189 - val_loss: 0.3339\n",
      "Epoch 36/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.3054 - val_loss: 0.3894\n",
      "Epoch 37/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.3026 - val_loss: 0.3337\n",
      "Epoch 38/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.3103 - val_loss: 0.3336\n",
      "Epoch 39/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.3070 - val_loss: 0.3321\n",
      "Epoch 40/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.3057 - val_loss: 0.3332\n",
      "Epoch 41/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.3010 - val_loss: 0.3595\n",
      "Epoch 42/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.3139 - val_loss: 0.3462\n",
      "Epoch 43/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.3224 - val_loss: 0.3320\n",
      "Epoch 44/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.2988 - val_loss: 0.3320\n",
      "Epoch 45/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.3048 - val_loss: 0.3351\n",
      "Epoch 46/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.2915 - val_loss: 0.3366\n",
      "Epoch 47/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.3070 - val_loss: 0.3387\n",
      "Epoch 48/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.2971 - val_loss: 0.3302\n",
      "Epoch 49/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.3224 - val_loss: 0.3442\n",
      "Epoch 50/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.3090 - val_loss: 0.3278\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
