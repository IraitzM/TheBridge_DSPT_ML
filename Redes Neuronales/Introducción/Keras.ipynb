{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rodri\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --user tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rodri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8 # SON TODOS LOS VALORES BINARIOS CON LOS QUE PUEDO REPRESENTAR ... "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "plt.imshow(X_train[0], cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_3, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01308247, -0.05060346,  0.02667752, ..., -0.00689939,\n",
       "         0.03117256, -0.05151217],\n",
       "       [ 0.01595513,  0.06764254,  0.0621572 , ..., -0.00529321,\n",
       "        -0.05273427,  0.02602755],\n",
       "       [-0.02461597, -0.05562878,  0.06979229, ...,  0.04093076,\n",
       "         0.05289011,  0.04585922],\n",
       "       ...,\n",
       "       [-0.06140877, -0.00419404,  0.01676651, ..., -0.06235111,\n",
       "         0.02265472,  0.02049723],\n",
       "       [-0.02676465,  0.0074866 , -0.01976896, ..., -0.00438808,\n",
       "        -0.01195922,  0.05570823],\n",
       "       [-0.00166915,  0.07136945,  0.02947927, ..., -0.06974004,\n",
       "        -0.03176472, -0.027267  ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784 # CAPAS APLANADAS = 784, Y CAPAS OCULTAS = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(), # STOCKASTED GRADIENT DISEGN, POR ESTA VIA SE CAMBIARÁN LOS PESOS \n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(), # LA FUNCIÓN DE PERDIDA ES UN SIMIL A LA FUNCIÓN OBJETIVO \n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()] # LA MÉTRICA, SE SABRÁ QUE TAN BIEN SE ESTÁ HACIENDO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "#  IMPORTANTE, ENTENDERLO BIEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4699 - loss: 1.8097 - val_accuracy: 0.8570 - val_loss: 0.6411\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.6052 - val_accuracy: 0.8939 - val_loss: 0.4071\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.4286 - val_accuracy: 0.9073 - val_loss: 0.3421\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.3638 - val_accuracy: 0.9151 - val_loss: 0.3092\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.3333 - val_accuracy: 0.9180 - val_loss: 0.2888\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.3081 - val_accuracy: 0.9200 - val_loss: 0.2726\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2865 - val_accuracy: 0.9275 - val_loss: 0.2576\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2799 - val_accuracy: 0.9294 - val_loss: 0.2494\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2605 - val_accuracy: 0.9331 - val_loss: 0.2378\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.2522 - val_accuracy: 0.9356 - val_loss: 0.2283\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2416 - val_accuracy: 0.9371 - val_loss: 0.2215\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.2280 - val_accuracy: 0.9406 - val_loss: 0.2120\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2200 - val_accuracy: 0.9423 - val_loss: 0.2058\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.2112 - val_accuracy: 0.9451 - val_loss: 0.1980\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.2061 - val_accuracy: 0.9471 - val_loss: 0.1924\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.2021 - val_accuracy: 0.9476 - val_loss: 0.1888\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1892 - val_accuracy: 0.9508 - val_loss: 0.1827\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1840 - val_accuracy: 0.9521 - val_loss: 0.1783\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1767 - val_accuracy: 0.9530 - val_loss: 0.1737\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1784 - val_accuracy: 0.9545 - val_loss: 0.1696\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1694 - val_accuracy: 0.9551 - val_loss: 0.1649\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1623 - val_accuracy: 0.9565 - val_loss: 0.1628\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1605 - val_accuracy: 0.9573 - val_loss: 0.1590\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1539 - val_accuracy: 0.9583 - val_loss: 0.1555\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1511 - val_accuracy: 0.9579 - val_loss: 0.1530\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1446 - val_accuracy: 0.9600 - val_loss: 0.1488\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1434 - val_accuracy: 0.9612 - val_loss: 0.1451\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1385 - val_accuracy: 0.9609 - val_loss: 0.1438\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1360 - val_accuracy: 0.9621 - val_loss: 0.1410\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1296 - val_accuracy: 0.9624 - val_loss: 0.1380\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1286 - val_accuracy: 0.9631 - val_loss: 0.1362\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.1237 - val_accuracy: 0.9639 - val_loss: 0.1335\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1217 - val_accuracy: 0.9638 - val_loss: 0.1325\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1216 - val_accuracy: 0.9648 - val_loss: 0.1299\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1175 - val_accuracy: 0.9647 - val_loss: 0.1287\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1142 - val_accuracy: 0.9651 - val_loss: 0.1260\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.1088 - val_accuracy: 0.9662 - val_loss: 0.1242\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.1123 - val_accuracy: 0.9667 - val_loss: 0.1228\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.1081 - val_accuracy: 0.9662 - val_loss: 0.1221\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.1027 - val_accuracy: 0.9674 - val_loss: 0.1205\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.1005 - val_accuracy: 0.9679 - val_loss: 0.1188\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0996 - val_accuracy: 0.9674 - val_loss: 0.1175\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0938 - val_accuracy: 0.9682 - val_loss: 0.1166\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.0971 - val_accuracy: 0.9689 - val_loss: 0.1142\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0940 - val_accuracy: 0.9693 - val_loss: 0.1131\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0886 - val_accuracy: 0.9690 - val_loss: 0.1136\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0838 - val_accuracy: 0.9699 - val_loss: 0.1108\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0870 - val_accuracy: 0.9702 - val_loss: 0.1096\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0851 - val_accuracy: 0.9697 - val_loss: 0.1090\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0837 - val_accuracy: 0.9711 - val_loss: 0.1077\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0823 - val_accuracy: 0.9684 - val_loss: 0.1133\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0816 - val_accuracy: 0.9712 - val_loss: 0.1053\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0797 - val_accuracy: 0.9713 - val_loss: 0.1033\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0749 - val_accuracy: 0.9721 - val_loss: 0.1020\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0747 - val_accuracy: 0.9719 - val_loss: 0.0998\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0698 - val_accuracy: 0.9722 - val_loss: 0.0995\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0681 - val_accuracy: 0.9725 - val_loss: 0.0979\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0678 - val_accuracy: 0.9731 - val_loss: 0.1003\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0609 - val_accuracy: 0.9725 - val_loss: 0.0942\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0595 - val_accuracy: 0.9741 - val_loss: 0.0955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17e02d15b20>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.6626999974250793, 0.8621000051498413, 0.8863599896430969, 0.8984400033950806, 0.906279981136322, 0.9124199748039246, 0.917959988117218, 0.9219800233840942, 0.9257199764251709, 0.9290000200271606, 0.932479977607727, 0.9350000023841858, 0.9377400279045105, 0.9402199983596802, 0.9422199726104736, 0.9435799717903137, 0.9456599950790405, 0.9472600221633911, 0.9488599896430969, 0.9510200023651123, 0.9522200226783752, 0.9532600045204163, 0.9546599984169006, 0.9561399817466736, 0.9575200080871582, 0.9585400223731995, 0.9599999785423279, 0.9608799815177917, 0.9623600244522095, 0.9629200100898743, 0.9640799760818481, 0.9649999737739563, 0.9661800265312195, 0.9665200114250183, 0.9676200151443481, 0.9686999917030334, 0.9694600105285645, 0.9698399901390076, 0.9702600240707397, 0.971560001373291, 0.9723600149154663, 0.9726200103759766, 0.9731400012969971, 0.9738799929618835, 0.9742400050163269, 0.9751799702644348, 0.975380003452301, 0.9758399724960327, 0.9763399958610535, 0.9768400192260742], 'loss': [1.3463783264160156, 0.539331316947937, 0.4100760221481323, 0.35867151618003845, 0.3277115523815155, 0.3052939176559448, 0.2872864305973053, 0.2723672688007355, 0.259306937456131, 0.24802076816558838, 0.2372433841228485, 0.22785748541355133, 0.21904872357845306, 0.2109091579914093, 0.20349372923374176, 0.19659732282161713, 0.1897936761379242, 0.18387392163276672, 0.1778811663389206, 0.1726352572441101, 0.16730014979839325, 0.16266728937625885, 0.15767702460289001, 0.15336614847183228, 0.14922377467155457, 0.1450933814048767, 0.14124374091625214, 0.13766741752624512, 0.1339937150478363, 0.13076366484165192, 0.1274394690990448, 0.12428052723407745, 0.12134134769439697, 0.11863131076097488, 0.11575482785701752, 0.11317888647317886, 0.11058925092220306, 0.10816557705402374, 0.10578706115484238, 0.10357660800218582, 0.10129286348819733, 0.09928005188703537, 0.09715461730957031, 0.09524750709533691, 0.09331583976745605, 0.09135396778583527, 0.08964487165212631, 0.08791018277406693, 0.08608945459127426, 0.0844007134437561], 'val_accuracy': [0.8569999933242798, 0.8938999772071838, 0.9072999954223633, 0.9150999784469604, 0.9179999828338623, 0.9200000166893005, 0.9275000095367432, 0.9294000267982483, 0.9330999851226807, 0.9355999827384949, 0.9370999932289124, 0.9405999779701233, 0.942300021648407, 0.9451000094413757, 0.9470999836921692, 0.9476000070571899, 0.9508000016212463, 0.9520999789237976, 0.953000009059906, 0.9545000195503235, 0.9550999999046326, 0.9564999938011169, 0.9573000073432922, 0.958299994468689, 0.9578999876976013, 0.9599999785423279, 0.9611999988555908, 0.9609000086784363, 0.9621000289916992, 0.9624000191688538, 0.963100016117096, 0.9639000296592712, 0.9638000130653381, 0.9648000001907349, 0.9646999835968018, 0.9650999903678894, 0.9661999940872192, 0.96670001745224, 0.9661999940872192, 0.9674000144004822, 0.9678999781608582, 0.9674000144004822, 0.9682000279426575, 0.9689000248908997, 0.9692999720573425, 0.968999981880188, 0.9699000120162964, 0.9702000021934509, 0.9696999788284302, 0.9710999727249146], 'val_loss': [0.6410601735115051, 0.40707120299339294, 0.34213095903396606, 0.30921080708503723, 0.2888392210006714, 0.27264055609703064, 0.25755012035369873, 0.24941867589950562, 0.23776781558990479, 0.22830834984779358, 0.22151066362857819, 0.21200478076934814, 0.2057630568742752, 0.19799388945102692, 0.19237008690834045, 0.18875017762184143, 0.1826629638671875, 0.17828504741191864, 0.17371411621570587, 0.16958755254745483, 0.16494537889957428, 0.16277652978897095, 0.15902948379516602, 0.15547990798950195, 0.1530330628156662, 0.14879746735095978, 0.1451493203639984, 0.14380034804344177, 0.14104659855365753, 0.13800974190235138, 0.13621261715888977, 0.13350225985050201, 0.13254563510417938, 0.1298571228981018, 0.12871858477592468, 0.12604546546936035, 0.12423805147409439, 0.12278924882411957, 0.12213270366191864, 0.12045565247535706, 0.11875808984041214, 0.11754447221755981, 0.11656516045331955, 0.11415418982505798, 0.11309883743524551, 0.11359583586454391, 0.11083244532346725, 0.10955271869897842, 0.10904930531978607, 0.10769127309322357]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6626999974250793,\n",
       "  0.8621000051498413,\n",
       "  0.8863599896430969,\n",
       "  0.8984400033950806,\n",
       "  0.906279981136322,\n",
       "  0.9124199748039246,\n",
       "  0.917959988117218,\n",
       "  0.9219800233840942,\n",
       "  0.9257199764251709,\n",
       "  0.9290000200271606,\n",
       "  0.932479977607727,\n",
       "  0.9350000023841858,\n",
       "  0.9377400279045105,\n",
       "  0.9402199983596802,\n",
       "  0.9422199726104736,\n",
       "  0.9435799717903137,\n",
       "  0.9456599950790405,\n",
       "  0.9472600221633911,\n",
       "  0.9488599896430969,\n",
       "  0.9510200023651123,\n",
       "  0.9522200226783752,\n",
       "  0.9532600045204163,\n",
       "  0.9546599984169006,\n",
       "  0.9561399817466736,\n",
       "  0.9575200080871582,\n",
       "  0.9585400223731995,\n",
       "  0.9599999785423279,\n",
       "  0.9608799815177917,\n",
       "  0.9623600244522095,\n",
       "  0.9629200100898743,\n",
       "  0.9640799760818481,\n",
       "  0.9649999737739563,\n",
       "  0.9661800265312195,\n",
       "  0.9665200114250183,\n",
       "  0.9676200151443481,\n",
       "  0.9686999917030334,\n",
       "  0.9694600105285645,\n",
       "  0.9698399901390076,\n",
       "  0.9702600240707397,\n",
       "  0.971560001373291,\n",
       "  0.9723600149154663,\n",
       "  0.9726200103759766,\n",
       "  0.9731400012969971,\n",
       "  0.9738799929618835,\n",
       "  0.9742400050163269,\n",
       "  0.9751799702644348,\n",
       "  0.975380003452301,\n",
       "  0.9758399724960327,\n",
       "  0.9763399958610535,\n",
       "  0.9768400192260742],\n",
       " 'loss': [1.3463783264160156,\n",
       "  0.539331316947937,\n",
       "  0.4100760221481323,\n",
       "  0.35867151618003845,\n",
       "  0.3277115523815155,\n",
       "  0.3052939176559448,\n",
       "  0.2872864305973053,\n",
       "  0.2723672688007355,\n",
       "  0.259306937456131,\n",
       "  0.24802076816558838,\n",
       "  0.2372433841228485,\n",
       "  0.22785748541355133,\n",
       "  0.21904872357845306,\n",
       "  0.2109091579914093,\n",
       "  0.20349372923374176,\n",
       "  0.19659732282161713,\n",
       "  0.1897936761379242,\n",
       "  0.18387392163276672,\n",
       "  0.1778811663389206,\n",
       "  0.1726352572441101,\n",
       "  0.16730014979839325,\n",
       "  0.16266728937625885,\n",
       "  0.15767702460289001,\n",
       "  0.15336614847183228,\n",
       "  0.14922377467155457,\n",
       "  0.1450933814048767,\n",
       "  0.14124374091625214,\n",
       "  0.13766741752624512,\n",
       "  0.1339937150478363,\n",
       "  0.13076366484165192,\n",
       "  0.1274394690990448,\n",
       "  0.12428052723407745,\n",
       "  0.12134134769439697,\n",
       "  0.11863131076097488,\n",
       "  0.11575482785701752,\n",
       "  0.11317888647317886,\n",
       "  0.11058925092220306,\n",
       "  0.10816557705402374,\n",
       "  0.10578706115484238,\n",
       "  0.10357660800218582,\n",
       "  0.10129286348819733,\n",
       "  0.09928005188703537,\n",
       "  0.09715461730957031,\n",
       "  0.09524750709533691,\n",
       "  0.09331583976745605,\n",
       "  0.09135396778583527,\n",
       "  0.08964487165212631,\n",
       "  0.08791018277406693,\n",
       "  0.08608945459127426,\n",
       "  0.0844007134437561],\n",
       " 'val_accuracy': [0.8569999933242798,\n",
       "  0.8938999772071838,\n",
       "  0.9072999954223633,\n",
       "  0.9150999784469604,\n",
       "  0.9179999828338623,\n",
       "  0.9200000166893005,\n",
       "  0.9275000095367432,\n",
       "  0.9294000267982483,\n",
       "  0.9330999851226807,\n",
       "  0.9355999827384949,\n",
       "  0.9370999932289124,\n",
       "  0.9405999779701233,\n",
       "  0.942300021648407,\n",
       "  0.9451000094413757,\n",
       "  0.9470999836921692,\n",
       "  0.9476000070571899,\n",
       "  0.9508000016212463,\n",
       "  0.9520999789237976,\n",
       "  0.953000009059906,\n",
       "  0.9545000195503235,\n",
       "  0.9550999999046326,\n",
       "  0.9564999938011169,\n",
       "  0.9573000073432922,\n",
       "  0.958299994468689,\n",
       "  0.9578999876976013,\n",
       "  0.9599999785423279,\n",
       "  0.9611999988555908,\n",
       "  0.9609000086784363,\n",
       "  0.9621000289916992,\n",
       "  0.9624000191688538,\n",
       "  0.963100016117096,\n",
       "  0.9639000296592712,\n",
       "  0.9638000130653381,\n",
       "  0.9648000001907349,\n",
       "  0.9646999835968018,\n",
       "  0.9650999903678894,\n",
       "  0.9661999940872192,\n",
       "  0.96670001745224,\n",
       "  0.9661999940872192,\n",
       "  0.9674000144004822,\n",
       "  0.9678999781608582,\n",
       "  0.9674000144004822,\n",
       "  0.9682000279426575,\n",
       "  0.9689000248908997,\n",
       "  0.9692999720573425,\n",
       "  0.968999981880188,\n",
       "  0.9699000120162964,\n",
       "  0.9702000021934509,\n",
       "  0.9696999788284302,\n",
       "  0.9710999727249146],\n",
       " 'val_loss': [0.6410601735115051,\n",
       "  0.40707120299339294,\n",
       "  0.34213095903396606,\n",
       "  0.30921080708503723,\n",
       "  0.2888392210006714,\n",
       "  0.27264055609703064,\n",
       "  0.25755012035369873,\n",
       "  0.24941867589950562,\n",
       "  0.23776781558990479,\n",
       "  0.22830834984779358,\n",
       "  0.22151066362857819,\n",
       "  0.21200478076934814,\n",
       "  0.2057630568742752,\n",
       "  0.19799388945102692,\n",
       "  0.19237008690834045,\n",
       "  0.18875017762184143,\n",
       "  0.1826629638671875,\n",
       "  0.17828504741191864,\n",
       "  0.17371411621570587,\n",
       "  0.16958755254745483,\n",
       "  0.16494537889957428,\n",
       "  0.16277652978897095,\n",
       "  0.15902948379516602,\n",
       "  0.15547990798950195,\n",
       "  0.1530330628156662,\n",
       "  0.14879746735095978,\n",
       "  0.1451493203639984,\n",
       "  0.14380034804344177,\n",
       "  0.14104659855365753,\n",
       "  0.13800974190235138,\n",
       "  0.13621261715888977,\n",
       "  0.13350225985050201,\n",
       "  0.13254563510417938,\n",
       "  0.1298571228981018,\n",
       "  0.12871858477592468,\n",
       "  0.12604546546936035,\n",
       "  0.12423805147409439,\n",
       "  0.12278924882411957,\n",
       "  0.12213270366191864,\n",
       "  0.12045565247535706,\n",
       "  0.11875808984041214,\n",
       "  0.11754447221755981,\n",
       "  0.11656516045331955,\n",
       "  0.11415418982505798,\n",
       "  0.11309883743524551,\n",
       "  0.11359583586454391,\n",
       "  0.11083244532346725,\n",
       "  0.10955271869897842,\n",
       "  0.10904930531978607,\n",
       "  0.10769127309322357]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.66270</td>\n",
       "      <td>1.346378</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.641060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86210</td>\n",
       "      <td>0.539331</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.407071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88636</td>\n",
       "      <td>0.410076</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.342131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.89844</td>\n",
       "      <td>0.358672</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.309211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90628</td>\n",
       "      <td>0.327712</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.288839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91242</td>\n",
       "      <td>0.305294</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.272641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.91796</td>\n",
       "      <td>0.287286</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.257550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92198</td>\n",
       "      <td>0.272367</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.249419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92572</td>\n",
       "      <td>0.259307</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.237768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.92900</td>\n",
       "      <td>0.248021</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.228308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93248</td>\n",
       "      <td>0.237243</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.221511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93500</td>\n",
       "      <td>0.227857</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.212005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93774</td>\n",
       "      <td>0.219049</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.205763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94022</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.197994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94222</td>\n",
       "      <td>0.203494</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.192370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94358</td>\n",
       "      <td>0.196597</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.188750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94566</td>\n",
       "      <td>0.189794</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.182663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94726</td>\n",
       "      <td>0.183874</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.178285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.94886</td>\n",
       "      <td>0.177881</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.173714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95102</td>\n",
       "      <td>0.172635</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.169588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95222</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.164945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95326</td>\n",
       "      <td>0.162667</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.162777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95466</td>\n",
       "      <td>0.157677</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.159029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95614</td>\n",
       "      <td>0.153366</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.155480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95752</td>\n",
       "      <td>0.149224</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.153033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95854</td>\n",
       "      <td>0.145093</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.148797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.141244</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.145149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96088</td>\n",
       "      <td>0.137667</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96236</td>\n",
       "      <td>0.133994</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.141047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96292</td>\n",
       "      <td>0.130764</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.138010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96408</td>\n",
       "      <td>0.127439</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.136213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.124281</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.133502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96618</td>\n",
       "      <td>0.121341</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.132546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96652</td>\n",
       "      <td>0.118631</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.129857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96762</td>\n",
       "      <td>0.115755</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.128719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96870</td>\n",
       "      <td>0.113179</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.126045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96946</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.124238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.96984</td>\n",
       "      <td>0.108166</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.122789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97026</td>\n",
       "      <td>0.105787</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.122133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97156</td>\n",
       "      <td>0.103577</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.120456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97236</td>\n",
       "      <td>0.101293</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.118758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97262</td>\n",
       "      <td>0.099280</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.117544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97314</td>\n",
       "      <td>0.097155</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.116565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97388</td>\n",
       "      <td>0.095248</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.114154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97424</td>\n",
       "      <td>0.093316</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97518</td>\n",
       "      <td>0.091354</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.113596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97538</td>\n",
       "      <td>0.089645</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.110832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97584</td>\n",
       "      <td>0.087910</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.109553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97634</td>\n",
       "      <td>0.086089</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.109049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97684</td>\n",
       "      <td>0.084401</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.107691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.66270  1.346378        0.8570  0.641060\n",
       "1    0.86210  0.539331        0.8939  0.407071\n",
       "2    0.88636  0.410076        0.9073  0.342131\n",
       "3    0.89844  0.358672        0.9151  0.309211\n",
       "4    0.90628  0.327712        0.9180  0.288839\n",
       "5    0.91242  0.305294        0.9200  0.272641\n",
       "6    0.91796  0.287286        0.9275  0.257550\n",
       "7    0.92198  0.272367        0.9294  0.249419\n",
       "8    0.92572  0.259307        0.9331  0.237768\n",
       "9    0.92900  0.248021        0.9356  0.228308\n",
       "10   0.93248  0.237243        0.9371  0.221511\n",
       "11   0.93500  0.227857        0.9406  0.212005\n",
       "12   0.93774  0.219049        0.9423  0.205763\n",
       "13   0.94022  0.210909        0.9451  0.197994\n",
       "14   0.94222  0.203494        0.9471  0.192370\n",
       "15   0.94358  0.196597        0.9476  0.188750\n",
       "16   0.94566  0.189794        0.9508  0.182663\n",
       "17   0.94726  0.183874        0.9521  0.178285\n",
       "18   0.94886  0.177881        0.9530  0.173714\n",
       "19   0.95102  0.172635        0.9545  0.169588\n",
       "20   0.95222  0.167300        0.9551  0.164945\n",
       "21   0.95326  0.162667        0.9565  0.162777\n",
       "22   0.95466  0.157677        0.9573  0.159029\n",
       "23   0.95614  0.153366        0.9583  0.155480\n",
       "24   0.95752  0.149224        0.9579  0.153033\n",
       "25   0.95854  0.145093        0.9600  0.148797\n",
       "26   0.96000  0.141244        0.9612  0.145149\n",
       "27   0.96088  0.137667        0.9609  0.143800\n",
       "28   0.96236  0.133994        0.9621  0.141047\n",
       "29   0.96292  0.130764        0.9624  0.138010\n",
       "30   0.96408  0.127439        0.9631  0.136213\n",
       "31   0.96500  0.124281        0.9639  0.133502\n",
       "32   0.96618  0.121341        0.9638  0.132546\n",
       "33   0.96652  0.118631        0.9648  0.129857\n",
       "34   0.96762  0.115755        0.9647  0.128719\n",
       "35   0.96870  0.113179        0.9651  0.126045\n",
       "36   0.96946  0.110589        0.9662  0.124238\n",
       "37   0.96984  0.108166        0.9667  0.122789\n",
       "38   0.97026  0.105787        0.9662  0.122133\n",
       "39   0.97156  0.103577        0.9674  0.120456\n",
       "40   0.97236  0.101293        0.9679  0.118758\n",
       "41   0.97262  0.099280        0.9674  0.117544\n",
       "42   0.97314  0.097155        0.9682  0.116565\n",
       "43   0.97388  0.095248        0.9689  0.114154\n",
       "44   0.97424  0.093316        0.9693  0.113099\n",
       "45   0.97518  0.091354        0.9690  0.113596\n",
       "46   0.97538  0.089645        0.9699  0.110832\n",
       "47   0.97584  0.087910        0.9702  0.109553\n",
       "48   0.97634  0.086089        0.9697  0.109049\n",
       "49   0.97684  0.084401        0.9711  0.107691"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "###### IMPORTANTE, ANALIZAR EL GRÁFICO #####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9668 - loss: 0.1099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09411758184432983, 0.9715999960899353]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.23491445e-05, 2.13490722e-07, 2.08955011e-04, 2.13072635e-03,\n",
       "        4.23876628e-07, 1.16217680e-05, 1.74623427e-10, 9.97554004e-01,\n",
       "        2.89603349e-06, 7.87223980e-05]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=colormaps.get(\"Greys\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 966,    0,    1,    2,    2,    1,    6,    1,    1,    0],\n",
       "       [   0, 1122,    4,    0,    0,    1,    4,    1,    3,    0],\n",
       "       [   4,    2, 1009,    2,    3,    0,    3,    7,    2,    0],\n",
       "       [   0,    0,    6,  979,    0,   10,    0,    8,    4,    3],\n",
       "       [   0,    0,    5,    1,  961,    0,    2,    2,    1,   10],\n",
       "       [   5,    1,    1,    7,    2,  861,    9,    1,    4,    1],\n",
       "       [   5,    3,    0,    1,    5,    7,  935,    0,    2,    0],\n",
       "       [   0,   10,   11,    2,    1,    1,    0,  997,    0,    6],\n",
       "       [   5,    2,    5,   10,    4,    6,    7,    5,  926,    4],\n",
       "       [   6,    5,    3,    5,   14,    4,    1,    9,    2,  960]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m108/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 2.2091 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 1.3757 - val_loss: 0.5292\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 1.4780 - val_loss: 0.4820\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.5802 - val_loss: 0.4254\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.4972 - val_loss: 0.4095\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.4492 - val_loss: 0.3970\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.4480 - val_loss: 0.3858\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.4544 - val_loss: 0.3759\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.4212 - val_loss: 0.3707\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.4277 - val_loss: 0.3688\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.4074 - val_loss: 0.3618\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4119 - val_loss: 0.3569\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 0.3923 - val_loss: 0.3533\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 0.4075 - val_loss: 0.3497\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.4247 - val_loss: 0.3439\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 0.3872 - val_loss: 0.3471\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3837 - val_loss: 0.3573\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.4053 - val_loss: 0.3454\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 0.3883 - val_loss: 0.3482\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.3905 - val_loss: 0.3457\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 0.3972 - val_loss: 0.3441\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3494\n",
      "0.34701210260391235\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.791687 ],\n",
       "       [2.381969 ],\n",
       "       [1.5542482],\n",
       "       [1.2833018],\n",
       "       [1.3557737]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3869\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3832\n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 0.3735\n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.3637\n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.3766\n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.3841\n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3572\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 0.3692\n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.3570\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3679\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.3651\n",
      "Epoch 12/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3527\n",
      "Epoch 13/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3731  \n",
      "Epoch 14/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 0.3510\n",
      "Epoch 15/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.3575\n",
      "Epoch 16/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3650\n",
      "Epoch 17/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.3522\n",
      "Epoch 18/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3447\n",
      "Epoch 19/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.3548\n",
      "Epoch 20/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 0.3503\n",
      "Epoch 21/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 0.4761\n",
      "Epoch 22/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.4088\n",
      "Epoch 23/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.3562\n",
      "Epoch 24/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.3482\n",
      "Epoch 25/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3666\n",
      "Epoch 26/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3750\n",
      "Epoch 27/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 0.3413\n",
      "Epoch 28/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3334\n",
      "Epoch 29/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.3409\n",
      "Epoch 30/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.3250\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.3374 - val_loss: 0.3142\n",
      "Epoch 2/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3418 - val_loss: 0.3014\n",
      "Epoch 3/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.3375 - val_loss: 0.3123\n",
      "Epoch 4/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.3489 - val_loss: 0.3018\n",
      "Epoch 5/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.3342 - val_loss: 0.3046\n",
      "Epoch 6/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.3307 - val_loss: 0.3054\n",
      "Epoch 7/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.3338 - val_loss: 0.3035\n",
      "Epoch 8/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.3437 - val_loss: 0.3079\n",
      "Epoch 9/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.3220 - val_loss: 0.3084\n",
      "Epoch 10/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.3242 - val_loss: 0.3012\n",
      "Epoch 11/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.3333 - val_loss: 0.3052\n",
      "Epoch 12/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.3281 - val_loss: 0.3050\n",
      "Epoch 13/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.3452 - val_loss: 0.3171\n",
      "Epoch 14/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.3374 - val_loss: 0.3080\n",
      "Epoch 15/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.3471 - val_loss: 0.3025\n",
      "Epoch 16/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.3487 - val_loss: 0.3154\n",
      "Epoch 17/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.4162 - val_loss: 0.3100\n",
      "Epoch 18/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.3478 - val_loss: 0.3030\n",
      "Epoch 19/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.3303 - val_loss: 0.3102\n",
      "Epoch 20/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.3325 - val_loss: 0.3044\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
